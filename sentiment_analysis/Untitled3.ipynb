{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da6fb3-2907-483f-b05c-a9439279d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528997af-a0e0-4d48-90aa-3973044e776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch numpy scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac49896-cbe9-476b-900e-ae06d5841f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9da4aa-600f-4103-b43c-41d553e3e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878fe77-9476-44ba-afe9-0107d1f8da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7d1bf-c963-40da-bc3e-914cd16b6424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('sentiment_data.csv')\n",
    "\n",
    "# Preprocess data (tokenization, etc.)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize text\n",
    "def tokenize_text(text, max_length=128):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, return_tensors=\"pt\", max_length=max_length)\n",
    "\n",
    "# Encode the text data\n",
    "data['input_ids'] = data['text'].apply(lambda x: tokenize_text(x)['input_ids'][0])\n",
    "data['attention_mask'] = data['text'].apply(lambda x: tokenize_text(x)['attention_mask'][0])\n",
    "\n",
    "# Encode labels (0: negative, 1: neutral, 2: positive)\n",
    "label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "data['label'] = data['sentiment'].map(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828c1dd-8e3a-40cf-85a3-976c70f9bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Initialize BERT for Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc69af8-081e-4e54-8c86-661d5c28d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to generate embeddings from BERT\n",
    "def get_bert_embeddings(input_ids, attention_mask):\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.last_hidden_state[:, 0, :]  # Use [CLS] token representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e111f-a920-4160-95d4-7f51c88a906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Support and Query Set Creatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d4799-fc9e-40f5-99bf-00014b766b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create support and query sets\n",
    "def create_support_and_query_sets(data, num_support_per_class=10):\n",
    "    support_set = []\n",
    "    query_set = []\n",
    "\n",
    "    for label in label_map.values():\n",
    "        class_data = data[data['label'] == label]\n",
    "        support_samples = class_data.sample(n=num_support_per_class)\n",
    "        query_samples = class_data.drop(support_samples.index)\n",
    "\n",
    "        support_set.append(support_samples)\n",
    "        query_set.append(query_samples)\n",
    "\n",
    "    support_set = pd.concat(support_set)\n",
    "    query_set = pd.concat(query_set)\n",
    "\n",
    "    return support_set, query_set\n",
    "\n",
    "# Create support and query sets\n",
    "support_set, query_set = create_support_and_query_sets(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f315b7-c5d8-4857-bd76-67ce35ce492d",
   "metadata": {},
   "outputs": [],
   "source": [
    " Calculate Prototypes (Class Mean Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326e841-a1a9-4c46-ba47-7a6247e47670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class prototypes\n",
    "def calculate_prototypes(support_set):\n",
    "    prototypes = {}\n",
    "\n",
    "    for label in label_map.values():\n",
    "        class_support = support_set[support_set['label'] == label]\n",
    "        input_ids = torch.stack(class_support['input_ids'].values.tolist())\n",
    "        attention_mask = torch.stack(class_support['attention_mask'].values.tolist())\n",
    "\n",
    "        # Get BERT embeddings\n",
    "        embeddings = get_bert_embeddings(input_ids, attention_mask)\n",
    "        prototype = torch.mean(embeddings, dim=0)\n",
    "\n",
    "        prototypes[label] = prototype\n",
    "\n",
    "    return prototypes\n",
    "\n",
    "prototypes = calculate_prototypes(support_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9714e3-fd28-45b1-84ef-87fb42d6397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Query Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4aeed2-ae90-48db-96a3-252aa7824b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify a query example\n",
    "def classify_query(query_embedding, prototypes):\n",
    "    distances = {label: F.pairwise_distance(query_embedding, prototype.unsqueeze(0)) for label, prototype in prototypes.items()}\n",
    "    predicted_label = min(distances, key=distances.get)\n",
    "    return predicted_label\n",
    "\n",
    "# Classify all query examples\n",
    "def classify_queries(query_set, prototypes):\n",
    "    predictions = []\n",
    "    true_labels = query_set['label'].tolist()\n",
    "\n",
    "    for _, row in query_set.iterrows():\n",
    "        input_ids = row['input_ids'].unsqueeze(0)\n",
    "        attention_mask = row['attention_mask'].unsqueeze(0)\n",
    "\n",
    "        # Get embedding for the query\n",
    "        query_embedding = get_bert_embeddings(input_ids, attention_mask)\n",
    "        \n",
    "        # Classify the query\n",
    "        predicted_label = classify_query(query_embedding, prototypes)\n",
    "        predictions.append(predicted_label)\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "predictions, true_labels = classify_queries(query_set, prototypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d3a34-3e2d-4f20-8406-842fea7d5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training and Updating BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19faee4a-935e-44e9-98c6-d47fa96299b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(bert_model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training function\n",
    "def train_prototypical_network(support_set, query_set, prototypes):\n",
    "    bert_model.train()\n",
    "\n",
    "    # For each query example\n",
    "    for _, row in query_set.iterrows():\n",
    "        input_ids = row['input_ids'].unsqueeze(0)\n",
    "        attention_mask = row['attention_mask'].unsqueeze(0)\n",
    "        true_label = row['label']\n",
    "\n",
    "        # Get query embedding\n",
    "        query_embedding = get_bert_embeddings(input_ids, attention_mask)\n",
    "\n",
    "        # Calculate distance to correct class prototype\n",
    "        correct_prototype = prototypes[true_label]\n",
    "        distance = F.pairwise_distance(query_embedding, correct_prototype.unsqueeze(0))\n",
    "\n",
    "        # Loss is the distance to the correct prototype\n",
    "        loss = distance.mean()\n",
    "\n",
    "        # Backpropagate and update model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Train the model for a number of episodes\n",
    "for episode in range(10):\n",
    "    support_set, query_set = create_support_and_query_sets(data)\n",
    "    prototypes = calculate_prototypes(support_set)\n",
    "    train_prototypical_network(support_set, query_set, prototypes)\n",
    "\n",
    "    # Classify queries after training\n",
    "    predictions, true_labels = classify_queries(query_set, prototypes)\n",
    "\n",
    "    # Evaluate performance\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f'Episode {episode + 1} - Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6124c1d-ecb5-46ef-b495-cab4e190448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3588217-e8eb-490e-a637-158b1673062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=label_map.keys()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
