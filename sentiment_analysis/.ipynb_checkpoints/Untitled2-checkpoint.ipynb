{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcf201-bccb-48a3-96a8-ff77c64c3593",
   "metadata": {},
   "outputs": [],
   "source": [
    "Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eaa82e-bbe3-4070-a224-0d85c36fe293",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch adapter-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf271657-af58-4ac4-afdd-a57925885979",
   "metadata": {},
   "outputs": [],
   "source": [
    "Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a460904-71ad-4e5f-98a1-b97d43073fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers.adapters import BertAdapterModel, AdapterConfig\n",
    "from lora import LoRAConfig, apply_lora\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457caa87-6c73-4614-9179-6d965ea98270",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d0010-5854-463a-afe7-d1fcd01e9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed datasets\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "val_df = pd.read_csv('val_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Check the first few rows\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d301c96-4db3-4aa6-b8b2-8676b8ec07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocess Data for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621749e1-e8f3-4c85-aefa-bf7504ef9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function for BERT\n",
    "def preprocess_data(texts, tokenizer, max_length=128):\n",
    "    return tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_length)\n",
    "\n",
    "# Apply tokenization on the training, validation, and test data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "X_train = preprocess_data(train_df['text'].tolist(), tokenizer)\n",
    "y_train = torch.tensor(train_df['sentiment'].tolist())\n",
    "\n",
    "X_val = preprocess_data(val_df['text'].tolist(), tokenizer)\n",
    "y_val = torch.tensor(val_df['sentiment'].tolist())\n",
    "\n",
    "X_test = preprocess_data(test_df['text'].tolist(), tokenizer)\n",
    "y_test = torch.tensor(test_df['sentiment'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cb450-6f0c-4d2b-aa63-8732135e9fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adapter Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ef487-982b-4bd0-a6b4-3354ec6eedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT with Adapters\n",
    "adapter_model = BertAdapterModel.from_pretrained('bert-large-uncased', num_labels=3)\n",
    "\n",
    "# Add an adapter and set it to training mode\n",
    "config = AdapterConfig(hidden_size=128, reduction_factor=16)  # Intermediate size of adapters: 128 perceptrons\n",
    "adapter_model.add_adapter(\"sentiment_adapter\", config=config)\n",
    "adapter_model.train_adapter(\"sentiment_adapter\")\n",
    "\n",
    "# Set the adapter model to train mode\n",
    "adapter_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c641549-d41e-430b-9ddf-ccdd27a70e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoRA Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7b60b-75fa-4f36-8255-8976c6c283a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model and apply LoRA fine-tuning\n",
    "lora_model = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=3)\n",
    "\n",
    "# Apply LoRA to specific layers of BERT\n",
    "lora_config = LoRAConfig(r=8)\n",
    "apply_lora(lora_model, config=lora_config, target_modules=['encoder.layer'])\n",
    "\n",
    "# Set the LoRA model to train mode\n",
    "lora_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430cd51d-0faa-4b80-ad0c-6328154b3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c277b9-44a7-48e5-8e95-dced34807508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, X_train, y_train, X_val, y_val, epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**X_train, labels=y_train)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Loss: {loss.item()}')\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**X_val)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        accuracy = accuracy_score(y_val, preds)\n",
    "        report = classification_report(y_val, preds, target_names=['negative', 'neutral', 'positive'])\n",
    "    \n",
    "    return accuracy, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc8641-69fb-4c36-be51-c3d9dd3dda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f34c0-8567-4a02-9e15-792526899b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer for each model\n",
    "adapter_optimizer = AdamW(adapter_model.parameters(), lr=1e-5)\n",
    "lora_optimizer = AdamW(lora_model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7681bcb-0cb2-48f3-a7bc-b2d3d44cac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train Adapter Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b067b-9394-4efe-bf59-0697b88ea22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the adapter model\n",
    "adapter_acc, adapter_report = train_model(adapter_model, adapter_optimizer, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Print results\n",
    "print(\"Adapter Model Validation Accuracy:\", adapter_acc)\n",
    "print(\"Adapter Model Classification Report:\\n\", adapter_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976e432-ca58-4574-a4db-1cde7aecf1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train LoRA Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f726dec7-ddf2-47fe-8749-806c67e1b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LoRA model\n",
    "lora_acc, lora_report = train_model(lora_model, lora_optimizer, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Print results\n",
    "print(\"LoRA Model Validation Accuracy:\", lora_acc)\n",
    "print(\"LoRA Model Classification Report:\\n\", lora_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3704b-c3cb-499e-8b0a-673d136ca0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test Both Models on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9b550-6187-4c18-ad42-30d5eac0aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**X_test)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        report = classification_report(y_test, preds, target_names=['negative', 'neutral', 'positive'])\n",
    "    \n",
    "    return accuracy, report\n",
    "\n",
    "# Test Adapter Model\n",
    "adapter_test_acc, adapter_test_report = evaluate_model(adapter_model, X_test, y_test)\n",
    "print(\"Adapter Model Test Accuracy:\", adapter_test_acc)\n",
    "print(\"Adapter Model Test Classification Report:\\n\", adapter_test_report)\n",
    "\n",
    "# Test LoRA Model\n",
    "lora_test_acc, lora_test_report = evaluate_model(lora_model, X_test, y_test)\n",
    "print(\"LoRA Model Test Accuracy:\", lora_test_acc)\n",
    "print(\"LoRA Model Test Classification Report:\\n\", lora_test_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
